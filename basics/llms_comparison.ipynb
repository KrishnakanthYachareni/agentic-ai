{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key exists and begins gsk_\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would you approach creating a balanced ethical framework for AI decision-making that considers diverse cultural values while ensuring accountability and transparency in its applications?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Creating a balanced ethical framework for AI decision-making that respects diverse cultural values while ensuring accountability and transparency involves a multi-faceted approach. Here are the key steps and considerations:\n",
       "\n",
       "### 1. **Incorporate Diverse Stakeholder Engagement**\n",
       "   - **Inclusive Dialogue**: Engage a diverse range of stakeholders, including ethicists, technologists, policy-makers, community representatives, and users from various cultural backgrounds to gather a wide spectrum of perspectives.\n",
       "   - **Cultural Sensitivity**: Understand and respect different cultural values, norms, and ethical considerations that may influence perceptions of AI. This requires cultural competency training for AI developers and stakeholders.\n",
       "\n",
       "### 2. **Establish Core Ethical Principles**\n",
       "   - **Universal Ethical Principles**: Identify and agree on core principles such as fairness, accountability, transparency, privacy, and respect for human rights that can be adapted to different cultural contexts.\n",
       "   - **Cultural Adaptability**: Develop mechanisms to adapt these principles in ways that resonate with specific cultural values without compromising integrity.\n",
       "\n",
       "### 3. **Develop Clear Guidelines for AI Deployment**\n",
       "   - **Use Case Assessment**: Create guidelines that evaluate specific applications of AI based on potential cultural impacts, emphasizing sensitivity to local norms and customs.\n",
       "   - **Impact Assessments**: Require cultural impact assessments prior to deployment, ensuring that AI applications do not reinforce systemic biases or harm any communities.\n",
       "\n",
       "### 4. **Accountability Mechanisms**\n",
       "   - **Traceability and Auditability**: Implement systems that enable AI decisions to be traceable, allowing stakeholders to understand how decisions were made. This can involve logging algorithms, data sources, and decision pathways.\n",
       "   - **Reporting Structures**: Establish clear reporting mechanisms for grievances and incidents related to AI decisions, including culturally relevant pathways for stakeholders to voice concerns.\n",
       "\n",
       "### 5. **Transparency and Communication**\n",
       "   - **Explainable AI**: Focus on developing explainable AI models that provide clear justifications for their decisions in understandable language, respecting cultural variations in communication styles.\n",
       "   - **Stakeholder Education**: Invest in educational initiatives that raise awareness about AI technologies, their decision-making processes, and implications within various cultural contexts.\n",
       "\n",
       "### 6. **Regulatory Frameworks**\n",
       "   - **Adaptable Policies**: Advocate for adaptable regulatory frameworks that consider the nuances of different cultural contexts while upholding global ethical standards.\n",
       "   - **International Collaboration**: Foster international dialogue about AI ethics through collaborations with global organizations, ensuring a cross-cultural exchange of ideas and best practices.\n",
       "\n",
       "### 7. **Ongoing Evaluation and Iteration**\n",
       "   - **Feedback Loops**: Implement feedback mechanisms to continuously collect input from culturally diverse stakeholders post-deployment, allowing for iterative improvements to the AI systems and their ethical frameworks.\n",
       "   - **Regular Review**: Schedule periodic reviews of ethical guidelines and frameworks to adapt to evolving cultural understandings, technological advancements, and societal norms.\n",
       "\n",
       "### 8. **Foster Research and Development**\n",
       "   - **Cross-Disciplinary Collaboration**: Encourage research that examines the intersection of AI, ethics, and cultural studies to develop frameworks that are genuinely reflective of diverse cultural realities.\n",
       "\n",
       "By following these steps, we can create a balanced ethical framework for AI decision-making that is inclusive, accountable, and transparent, ultimately fostering trust and enhancing the social good across diverse cultures."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Creating a balanced ethical framework for AI decision-making that considers diverse cultural values while ensuring accountability and transparency is a complex challenge. Here's a multi-faceted approach:\n",
       "\n",
       "**I. Foundational Principles & Values:**\n",
       "\n",
       "1.  **Human-Centered Design:**  AI should be designed and deployed with the primary goal of benefiting humanity and respecting human dignity.  This principle acts as a constant guide.\n",
       "\n",
       "2.  **Respect for Cultural Diversity:** Acknowledge and respect the wide range of cultural values, norms, and beliefs that exist globally.  Avoid imposing a single, dominant cultural perspective.  Recognize that what is considered ethical in one culture might not be in another.\n",
       "\n",
       "3.  **Fairness and Non-Discrimination:** AI systems should be designed and used in ways that avoid unfair bias and discrimination.  This requires ongoing monitoring and mitigation of bias in data, algorithms, and outcomes.\n",
       "\n",
       "4.  **Transparency and Explainability:**  Strive for transparency in how AI systems make decisions. Where possible, provide explanations for decisions that are understandable to the affected individuals and stakeholders.  This might involve different levels of explanation depending on the context and audience.\n",
       "\n",
       "5.  **Accountability and Responsibility:**  Clearly define who is responsible for the actions and outcomes of AI systems.  This includes developers, deployers, and users.  Mechanisms for redress and accountability should be in place for any harms caused by AI.\n",
       "\n",
       "6.  **Privacy and Data Protection:**  AI systems should respect individuals' privacy and comply with relevant data protection regulations.  Data collection, storage, and usage should be transparent and consensual.\n",
       "\n",
       "7.  **Safety and Security:** AI systems should be designed and operated safely and securely to prevent unintended harm or malicious use.  Robust security measures are crucial.\n",
       "\n",
       "8.  **Sustainability:**  Consider the environmental impact of AI systems, including energy consumption and resource utilization.  Promote sustainable AI development and deployment.\n",
       "\n",
       "9.  **Beneficence and Non-Maleficence:**  Strive to maximize the benefits of AI while minimizing potential harms.  This requires careful consideration of potential risks and trade-offs.\n",
       "\n",
       "**II.  Development and Implementation Process:**\n",
       "\n",
       "1.  **Multi-Stakeholder Engagement:**  Involve a diverse group of stakeholders in the design, development, and deployment of AI systems.  This includes ethicists, domain experts, policymakers, developers, users, and representatives from different cultural backgrounds.\n",
       "\n",
       "2.  **Cultural Sensitivity Assessments:**  Conduct thorough cultural sensitivity assessments before deploying AI systems in new contexts.  This involves understanding the local cultural norms, values, and beliefs to identify potential ethical conflicts or unintended consequences.\n",
       "\n",
       "3.  **Data Diversity and Bias Mitigation:**  Ensure that the data used to train AI systems is diverse and representative of the populations it will affect.  Implement techniques to detect and mitigate bias in data, algorithms, and outcomes.\n",
       "\n",
       "4.  **Explainable AI (XAI) Techniques:**  Employ XAI techniques to make AI decisions more transparent and understandable.  Explore different XAI methods and choose the most appropriate one for each application.\n",
       "\n",
       "5.  **Auditing and Monitoring:**  Regularly audit and monitor AI systems to ensure that they are functioning as intended and that they are not causing unintended harm or discrimination.\n",
       "\n",
       "6.  **Feedback Mechanisms:**  Establish clear feedback mechanisms for individuals and communities to report concerns or issues related to AI systems.  Actively solicit and respond to feedback to improve the ethical performance of AI.\n",
       "\n",
       "7.  **Ethical Review Boards/Committees:**  Establish independent ethical review boards or committees to oversee the development and deployment of AI systems.  These boards should have the expertise to identify and address potential ethical risks.\n",
       "\n",
       "8.  **Education and Training:**  Provide education and training to developers, users, and policymakers on the ethical implications of AI and how to use AI responsibly.\n",
       "\n",
       "9.  **Adaptive Governance:**  Develop flexible and adaptable governance frameworks that can evolve as AI technology advances and societal values change.  Avoid rigid, top-down approaches.\n",
       "\n",
       "**III. Key Considerations for Accountability & Transparency:**\n",
       "\n",
       "1.  **Clear Lines of Responsibility:**  Establish clear lines of responsibility for the actions and outcomes of AI systems.  Identify who is accountable for specific decisions and actions.\n",
       "\n",
       "2.  **Documented Decision-Making Processes:**  Document the decision-making processes of AI systems, including the data used, the algorithms applied, and the reasoning behind the decisions.\n",
       "\n",
       "3.  **Auditable Algorithms:** Design algorithms that can be audited to ensure that they are fair and unbiased. This might involve using techniques like algorithm certification or independent audits.\n",
       "\n",
       "4.  **Explainable Output:**  Provide explanations for AI decisions that are understandable to the affected individuals and stakeholders.  The level of explanation should be appropriate for the context and audience.  Consider using visual explanations, simplified language, and personalized explanations.\n",
       "\n",
       "5.  **Right to Challenge:**  Provide individuals with the right to challenge AI decisions that affect them and to seek redress if they believe they have been unfairly treated.  Establish clear procedures for challenging decisions and resolving disputes.\n",
       "\n",
       "6.  **Independent Oversight:**  Establish independent oversight mechanisms to monitor the development and deployment of AI systems and to ensure that they are being used ethically.\n",
       "\n",
       "7.  **Open Source and Open Data (Where Appropriate):**  Promote open-source development and open data initiatives (while respecting privacy concerns) to foster transparency and collaboration in the AI community.\n",
       "\n",
       "8.  **Impact Assessments:**  Conduct thorough impact assessments before deploying AI systems to identify potential risks and benefits, including ethical, social, and environmental impacts.\n",
       "\n",
       "**IV.  Addressing Cultural Nuances:**\n",
       "\n",
       "*   **Contextual Ethics:** Recognize that ethical principles are not absolute and may vary depending on the cultural context. Develop frameworks that can adapt to different cultural norms and values.\n",
       "*   **Local Expertise:** Engage with local experts and communities to understand their cultural values and beliefs. This can help to identify potential ethical conflicts and to develop solutions that are culturally sensitive.\n",
       "*   **Translation and Localization:** Translate ethical guidelines and training materials into multiple languages and adapt them to local cultural contexts.\n",
       "*   **Representative Advisory Boards:**  Establish advisory boards with representation from diverse cultural backgrounds to provide guidance on ethical issues related to AI.\n",
       "*   **Scenario Planning:** Use scenario planning to anticipate potential ethical dilemmas in different cultural contexts and to develop strategies for addressing them.\n",
       "\n",
       "**V.  Overcoming Challenges:**\n",
       "\n",
       "*   **Defining \"Fairness\":**  Fairness is a complex and contested concept, and there is no single definition that is universally accepted.  Different cultures may have different notions of fairness.\n",
       "*   **Balancing Transparency and Privacy:**  Transparency is important for accountability, but it can also conflict with privacy.  It is important to find a balance between these two values.\n",
       "*   **Dynamic Nature of Culture:**  Cultural values are constantly evolving, so ethical frameworks must be flexible and adaptable.\n",
       "*   **Enforcement:**  Enforcing ethical guidelines and holding AI developers accountable can be challenging, especially in a globalized world.\n",
       "*   **Unforeseen Consequences:**  It is impossible to anticipate all of the potential consequences of AI, so ongoing monitoring and evaluation are essential.\n",
       "\n",
       "**Conclusion:**\n",
       "\n",
       "Creating a truly balanced ethical framework for AI requires a sustained and collaborative effort from all stakeholders.  It's a continuous process of learning, adaptation, and refinement.  By embracing these principles and strategies, we can work towards a future where AI is used in a way that is both beneficial and ethical for all of humanity.  It's not a one-size-fits-all solution, but a dynamic process of tailoring ethical principles to the specific context and cultural values in which AI is being deployed.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Creating a balanced ethical framework for AI decision-making that considers diverse cultural values while ensuring accountability and transparency in its applications requires a multi-faceted approach. Here's a step-by-step guide to help you develop such a framework:\n",
       "\n",
       "**I. Establish a Diverse and Inclusive Stakeholder Group**\n",
       "\n",
       "1. **Gather stakeholders**: Assemble a diverse group of stakeholders, including experts from various cultural backgrounds, ethics, philosophy, law, technology, and social sciences.\n",
       "2. **Ensure representation**: Ensure that the stakeholder group represents a broad range of cultural values, perspectives, and experiences.\n",
       "3. **Foster open dialogue**: Encourage open and respectful dialogue among stakeholders to facilitate the sharing of ideas and concerns.\n",
       "\n",
       "**II. Identify Core Ethical Principles**\n",
       "\n",
       "1. **Respect for human rights**: Incorporate respect for human rights, dignity, and well-being as fundamental principles.\n",
       "2. **Fairness and transparency**: Emphasize fairness, transparency, and explainability in AI decision-making processes.\n",
       "3. **Accountability**: Establish clear lines of accountability for AI-driven decisions and actions.\n",
       "4. **Cultural sensitivity**: Incorporate cultural sensitivity and awareness into the framework to ensure that AI systems respect diverse cultural values and norms.\n",
       "\n",
       "**III. Develop Cultural Value-Sensitive Guidelines**\n",
       "\n",
       "1. **Conduct cultural analysis**: Conduct thorough cultural analysis to identify and understand diverse cultural values and norms.\n",
       "2. **Guidelines for AI development**: Develop guidelines for AI development that take into account cultural values, such as:\n",
       "\t* Respect for human autonomy and decision-making capacity.\n",
       "\t* Consideration of cultural differences in communication styles and preferences.\n",
       "\t* Sensitivity to cultural nuances in data collection and analysis.\n",
       "3. **Regular updates and revision**: Regularly update and revise guidelines to reflect changing cultural values and new technological advancements.\n",
       "\n",
       "**IV. Ensure Accountability and Transparency**\n",
       "\n",
       "1. **Clear decision-making processes**: Establish clear and transparent decision-making processes for AI systems.\n",
       "2. **Explainability and interpretability**: Ensure that AI systems provide explanations and interpretations of their decisions and actions.\n",
       "3. **Regular audits and evaluations**: Conduct regular audits and evaluations to assess AI system performance, fairness, and cultural sensitivity.\n",
       "4. **Incident response plan**: Develop an incident response plan to address and mitigate potential harm caused by AI-driven decisions or actions.\n",
       "\n",
       "**V. Implement and Monitor the Framework**\n",
       "\n",
       "1. **Establish an oversight body**: Establish an oversight body to monitor and enforce the ethical framework.\n",
       "2. **Training and education**: Provide training and education for AI developers, users, and stakeholders on the ethical framework and its implementation.\n",
       "3. **Continuous monitoring and evaluation**: Continuously monitor and evaluate the effectiveness of the framework and make adjustments as needed.\n",
       "4. **Encourage public engagement**: Encourage public engagement and participation in the development and refinement of the ethical framework.\n",
       "\n",
       "**VI. Foster International Cooperation and Knowledge Sharing**\n",
       "\n",
       "1. **Collaborate with international organizations**: Collaborate with international organizations, such as the United Nations, to share knowledge and best practices.\n",
       "2. **Participate in global forums**: Participate in global forums and conferences to discuss and refine the ethical framework.\n",
       "3. **Develop global guidelines and standards**: Develop global guidelines and standards for AI ethics and cultural sensitivity.\n",
       "\n",
       "By following this multi-faceted approach, you can create a balanced ethical framework for AI decision-making that considers diverse cultural values while ensuring accountability and transparency in its applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
